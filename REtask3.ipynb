{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Helper notebook for loading the data and saving the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "from mvseg.mvseg.utils.experiments import load_experiment\n",
    "import glob\n",
    "import torch\n",
    "from mvseg.mvseg.datasets import get_dataset\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import signal\n",
    "import shutil\n",
    "import re\n",
    "import os\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from mvseg.mvseg.datasets import get_dataset\n",
    "from mvseg.settings import TRAINING_PATH\n",
    "from mvseg import logger\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        loaded_object = pickle.load(f)\n",
    "        return loaded_object\n",
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, make predictions and save prediction in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = load_zipped_pickle(\"/cluster/project/infk/cvg/students/alpaul/MitralValveSegmentation/data/train.pkl\")\n",
    "test_data = load_zipped_pickle(\"/cluster/project/infk/cvg/students/alpaul/MitralValveSegmentation/data/test.pkl\")\n",
    "# samples = load_zipped_pickle(\"sample.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get basic dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data info:\n",
      "    Number of train videos: 65\n",
      "    Min num frames in train videos: 54\n",
      "    Max num frames in train videos: 334\n",
      "    Average num of frames in train videos: 151.83076923076922\n",
      "Test data info:\n",
      "    Number of test videos: 20\n",
      "    Min num frames in test videos: 39\n",
      "    Max num frames in test videos: 125\n",
      "    Average num of frames in test videos: 75.35\n",
      "Shapes: [(586, 821, 103), (587, 791, 52), (583, 777, 69), (582, 851, 61), (732, 845, 53), (583, 809, 84), (582, 737, 78), (587, 775, 125), (730, 956, 76), (587, 781, 104), (583, 681, 68), (587, 713, 90), (587, 612, 78), (587, 773, 73), (707, 855, 39), (731, 1007, 72), (583, 780, 106), (583, 670, 63), (594, 745, 51), (583, 779, 62)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data info:\")\n",
    "print(f\"    Number of train videos: {np.array(train_data).shape[0]}\")\n",
    "print(f\"    Min num frames in train videos: {min([data['video'].shape[2] for data in train_data])}\")\n",
    "print(f\"    Max num frames in train videos: {max([data['video'].shape[2] for data in train_data])}\")\n",
    "print(f\"    Average num of frames in train videos: {np.mean([data['video'].shape[2] for data in train_data])}\")\n",
    "# print([np.array(train_data[i]['box']).shape for i in range(len(train_data))])\n",
    "\n",
    "print(f\"Test data info:\")\n",
    "print(f\"    Number of test videos: {np.array(test_data).shape[0]}\")\n",
    "print(f\"    Min num frames in test videos: {min([data['video'].shape[2] for data in test_data])}\")\n",
    "print(f\"    Max num frames in test videos: {max([data['video'].shape[2] for data in test_data])}\")\n",
    "print(f\"    Average num of frames in test videos: {np.mean([data['video'].shape[2] for data in test_data])}\")\n",
    "print(f\"Shapes: {[data['video'].shape for data in test_data]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create videos for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_videos_to_save = 65\n",
    "\n",
    "train = deepcopy(train_data)\n",
    "for i in range(num_videos_to_save):\n",
    "    video = train[i]['video']\n",
    "    box = np.array(train[i]['box'])\n",
    "    label = train[i]['label']\n",
    "    label = label.astype('float32')\n",
    "#     print(label)\n",
    "#     label = label*255\n",
    "#     print(list(label[train[i]['frames'][0]]))\n",
    "    label = np.moveaxis(label, -1, 0)\n",
    "    video = np.moveaxis(video, -1, 0)\n",
    "    first_image = video[0]\n",
    "    size = first_image.shape\n",
    "    fps = 10\n",
    "    out = cv2.VideoWriter(f'/cluster/project/infk/cvg/students/alpaul/MitralValveSegmentation/data/train_videos/{i}.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (size[1], size[0]), False)\n",
    "    for j in range(len(video)):\n",
    "        image = video[j]\n",
    "#         image[box] = 255\n",
    "        labelj = label[j]\n",
    "        image[labelj] = 255\n",
    "        box = box.astype('uint8')*255\n",
    "        label = label.astype('uint8')*255\n",
    "        out.write(image)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12/17/2022 19:29:48 mvseg INFO] Starting test exp2_stage2_ft\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "[]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22624/1038417400.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOmegaConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOmegaConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'num_workers'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdata_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MitralValveSegmentation/mvseg/mvseg/datasets/__init__.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/MitralValveSegmentation/mvseg/mvseg/utils/tools.py\u001b[0m in \u001b[0;36mget_class\u001b[0;34m(mod_name, base_path, BaseClass)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# Filter classes inherited from BaseModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: []"
     ]
    }
   ],
   "source": [
    "##### DATALOADER #####\n",
    "\n",
    "# Load model\n",
    "\n",
    "experiment = 'exp2_stage2_ft' # ['exp1_finetune_2_heads'] # ['exp1_box_gpu']\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "conf = '/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/configs/config_train.yaml'\n",
    "\n",
    "logger.info(f'Starting test {experiment}')\n",
    "\n",
    "output_dir = Path(TRAINING_PATH, experiment)\n",
    "conf = OmegaConf.merge(OmegaConf.load(conf), {'train':{'num_workers': 0}})\n",
    "data_conf = conf.data\n",
    "dataset = get_dataset(data_conf.name)(data_conf)\n",
    "test_loader = dataset.get_data_loader('test')\n",
    "model = load_experiment(experiment, conf.model)\n",
    "model = model.eval()\n",
    "\n",
    "loss_fn, metrics_fn = model.loss, model.metrics\n",
    "viz = []\n",
    "# all_experiments[experiment] = []\n",
    "\n",
    "\n",
    "#         all_experiments[experiment].append({\n",
    "#                         'L1_roll': error_roll.cpu().item(),\n",
    "#                         'L1_pitch': error_pitch,\n",
    "#                         'L1_fov': metrics['fov/L1_degree_loss'].cpu().item(),\n",
    "#                         'name': name,\n",
    "#                         **{'gt_'+str(gt_key):gts[gt_key].unsqueeze(0).cpu().item()  \n",
    "#                            if isinstance(gts[gt_key],torch.Tensor)\n",
    "#                            else gts[gt_key]\n",
    "#                            for gt_key in gts},\n",
    "#                         **{'pred_'+str(pred_key):preds[pred_key].unsqueeze(0).cpu().item()  \n",
    "#                            if isinstance(preds[pred_key],torch.Tensor)\n",
    "#                            else preds[pred_key]\n",
    "#                            for pred_key in preds}\n",
    "#                         })\n",
    "\n",
    "\n",
    "# Read all frames into list\n",
    "# resize if needed\n",
    "# feed through and get box output\n",
    "# if resized, resize back.\n",
    "# mask the image frame with the boxoutput and save to video\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|                                                                                      | 0/1507 [00:00<?, ?it/s]/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "Testing: 100%|###########################################################################| 1507/1507 [07:49<00:00,  3.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Box only\n",
    "from copy import deepcopy\n",
    "\n",
    "# count = 0\n",
    "fps = 10\n",
    "# out = cv2.VideoWriter(f'full_test_resize_WORKING.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (821, 586), False) # compatible 821, 586\n",
    "\n",
    "\n",
    "all_preds = {}\n",
    "all_images = {}\n",
    "\n",
    "count = 0\n",
    "for data in tqdm(test_loader, desc='Testing', ascii=True, disable=False):\n",
    "    count += 1\n",
    "    \n",
    "    with torch.no_grad():   \n",
    "        pred = model(data)\n",
    "        box_pred = pred['seg'].squeeze(0).squeeze(0)\n",
    "        h,w = data['hw']\n",
    "#         if not (h[0] == 586 and w[0] == 821):\n",
    "#             print(\"Skipping\")\n",
    "#             continue\n",
    "        box_pred = torch.tensor(resize(box_pred, (h[0],w[0]), anti_aliasing=True))\n",
    "        pred_box_mask = torch.gt(box_pred, 0.7)\n",
    "        pred_box_mask = pred_box_mask.numpy().astype('bool')\n",
    "#         im = data['image'].squeeze(0).squeeze(0)\n",
    "#         im = resize(im, (h[0],w[0]), anti_aliasing=True)\n",
    "#         print(im.shape, pred_box_mask.shape)\n",
    "#         print(type(im), type(pred_box_mask))\n",
    "#         assert im.shape == pred_box_mask.shape\n",
    "#         im = im * 255 * 255\n",
    "        \n",
    "#         im[pred_box_mask] = 255\n",
    "        \n",
    "#         im = im.astype('uint8')\n",
    "#         print(np.max(im), np.max(pred_box_mask))\n",
    "#         print(im)\n",
    "#         plt.imshow(im)\n",
    "\n",
    "\n",
    "        if data['video'][0] not in all_preds.keys():\n",
    "            all_preds[data['video'][0]] = [pred_box_mask]\n",
    "#             all_images[data['video'][0]] = [im]\n",
    "        else:\n",
    "            all_preds[data['video'][0]].append(pred_box_mask)\n",
    "#             all_images[data['video'][0]].append(im)\n",
    "#         out.write(im)\n",
    "#         if count >= 100:\n",
    "#             break\n",
    "\n",
    "#         print(type(im))\n",
    "#         out.write(pred_box_mask.numpy().astype('uint8'))\n",
    "        \n",
    "#         plt.imshow(pred_box_mask.numpy().astype('uint8'))\n",
    "\n",
    "# out.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E9AHVWGBUF': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], 'H7G0BX4HFV': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], '8FKMSXTPSJ': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], 'JANFS05F33': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], 'O7WUJ71C15': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], '1XHV0Q88M5': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], '401JD35E1A': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], 'VODEK84RH4': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], 'ONA22CCCFQ': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], '7UXIXUBK2G': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], 'ESY800XYMN': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], '571G03ZYDA': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], 'QZA3WA0E2X': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], 'JQX264DTZ0': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], 'TYM0IJW004': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], 'CD4RIAOCHG': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], 'D271IBSMUW': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], '0MVRNDWR1G': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], '1QSFD8ORNM': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])], 'UB7LFQKZT5': [tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]]), tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])]}\n"
     ]
    }
   ],
   "source": [
    "# Arrange it for prediction\n",
    "\n",
    "print(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|                                                                                               | 0/1507 [00:00<?, ?it/s]/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [12544], which does not match the required output shape [1, 1, 112, 112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "Testing:   5%|####2                                                                                 | 74/1507 [00:04<01:35, 14.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Sem only\n",
    "# count = 0\n",
    "# fps = 10\n",
    "# out = cv2.VideoWriter(f'test_1.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (112, 112), False)\n",
    "# for data in tqdm(test_loader, desc='Testing', ascii=True, disable=False):\n",
    "#     count += 1\n",
    "#     with torch.no_grad():\n",
    "# #         print(data)        \n",
    "#         pred = model(data)\n",
    "#         sem_pred = pred['sem_seg'].squeeze(0).squeeze(0)\n",
    "# #         print(torch.max(box_pred, dim=0))\n",
    "#         pred_sem_mask = torch.gt(sem_pred, 0.5)\n",
    "#         im = data['image'].squeeze(0).squeeze(0)\n",
    "        \n",
    "#         im = im.numpy() * 255 * 255\n",
    "# #         print(np.max(im, axis=0))\n",
    "# #         im = im.astype('uint8')\n",
    "#         im[pred_sem_mask] = 255.\n",
    "#         im = im.astype('uint8')\n",
    "# #         print(type(im))\n",
    "#         out.write(im)\n",
    "# #         plt.imshow(im)\n",
    "#         if count>=75:\n",
    "#             out.release()\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 586, 821)\n",
      "(52, 587, 791)\n",
      "(69, 583, 777)\n",
      "(61, 582, 851)\n",
      "(53, 732, 845)\n",
      "(84, 583, 809)\n",
      "(78, 582, 737)\n",
      "(125, 587, 775)\n",
      "(76, 730, 956)\n",
      "(104, 587, 781)\n",
      "(68, 583, 681)\n",
      "(90, 587, 713)\n",
      "(78, 587, 612)\n",
      "(73, 587, 773)\n",
      "(39, 707, 855)\n",
      "(72, 731, 1007)\n",
      "(106, 583, 780)\n",
      "(63, 583, 670)\n",
      "(51, 594, 745)\n",
      "(62, 583, 779)\n"
     ]
    }
   ],
   "source": [
    "# make prediction for test\n",
    "predictions = []\n",
    "for d in test_data:\n",
    "#     print(d['video'].shape) # this is what we need to resize to.\n",
    "#     prediction = np.array(np.zeros_like(d['video']), dtype=np.bool)\n",
    "\n",
    "\n",
    "    prediction = np.array([list(p) for p in all_preds[d['name']]])\n",
    "#     images = np.array([list(p) for p in all_images[d['name']]])\n",
    "#     print(images.shape, prediction.shape)\n",
    "    print(prediction.shape)\n",
    "    height = prediction.shape[1]\n",
    "    width = prediction.shape[2]\n",
    "#     out = cv2.VideoWriter(f'{d[\"name\"]}_0.75.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height), False)\n",
    "#     for i in range(len(prediction)):\n",
    "#         mask = (np.array(prediction[i])).astype('bool') #*255.).astype('uint8')\n",
    "#         print(mask)\n",
    "#         print(im.shape, mask.shape)\n",
    "#         im = (np.array(images[i])).astype('uint8')\n",
    "#         im[mask] = 255.\n",
    "#         im = np.array(images[i])\n",
    "#         out.write(mask.astype('uint8') * 255)\n",
    "    prediction = np.moveaxis(prediction, 0, -1)\n",
    "#     prediction[int(height/2)-50:int(height/2+50), int(width/2)-50:int(width/2+50)] = True\n",
    "    # DATA Structure\n",
    "    predictions.append({\n",
    "        'name': d['name'],\n",
    "        'prediction': prediction\n",
    "        }\n",
    "    )\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate videos during prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12/17/2022 19:35:23 mvseg INFO] Starting test exp2_stage2_ft\n",
      "[12/17/2022 19:35:23 mvseg.mvseg.datasets.base_dataset INFO] Creating dataset MVSegDataset\n",
      "[12/17/2022 19:35:44 mvseg.mvseg.utils.experiments INFO] Loading checkpoint checkpoint_best.tar\n"
     ]
    }
   ],
   "source": [
    "experiment = 'exp2_stage2_ft'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "conf = '/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/configs/config_train.yaml'\n",
    "logger.info(f'Starting test {experiment}')\n",
    "output_dir = Path(TRAINING_PATH, experiment)\n",
    "conf = OmegaConf.merge(OmegaConf.load(conf), {'train':{'num_workers': 0}})\n",
    "data_conf = conf.data\n",
    "dataset = get_dataset(data_conf.name)(data_conf)\n",
    "test_loader = dataset.get_data_loader('test')\n",
    "model = load_experiment(experiment, conf.model)\n",
    "model = model.eval()\n",
    "loss_fn, metrics_fn = model.loss, model.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through test dataset, and generate 1 video per test video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                 | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 586, 821)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                | 0/103 [00:00<?, ?it/s]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  1%|                                                                                       | 1/103 [00:03<06:10,  3.64s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  2%|                                                                                      | 2/103 [00:07<06:01,  3.58s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  3%|                                                                                     | 3/103 [00:10<06:02,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  4%|                                                                                    | 4/103 [00:14<05:57,  3.61s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  5%|                                                                                   | 5/103 [00:18<05:55,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  6%|                                                                                  | 6/103 [00:21<05:51,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  7%|                                                                                  | 7/103 [00:25<05:47,  3.62s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  8%|                                                                                 | 8/103 [00:28<05:43,  3.62s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  9%|                                                                                | 9/103 [00:32<05:38,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "  9%|                                                                                | 9/103 [00:36<06:17,  4.01s/it]\n",
      "  5%|                                                                                    | 1/20 [00:36<11:26, 36.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prediction list: (10, 586, 821)\n",
      "shape of prediction list: (586, 821, 10)\n",
      "(52, 587, 791)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                 | 0/52 [00:00<?, ?it/s]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  2%|                                                                                       | 1/52 [00:03<03:03,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  4%|                                                                                     | 2/52 [00:07<02:59,  3.58s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  6%|                                                                                   | 3/52 [00:10<02:56,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  8%|                                                                                  | 4/52 [00:14<02:53,  3.62s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 10%|                                                                                | 5/52 [00:18<02:50,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 12%|                                                                              | 6/52 [00:21<02:47,  3.64s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 13%|                                                                             | 7/52 [00:25<02:44,  3.65s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 15%|                                                                           | 8/52 [00:29<02:39,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 17%|                                                                         | 9/52 [00:32<02:36,  3.65s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      " 17%|                                                                         | 9/52 [00:36<02:53,  4.04s/it]\n",
      " 10%|                                                                                | 2/20 [01:12<10:52, 36.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prediction list: (10, 587, 791)\n",
      "shape of prediction list: (587, 791, 10)\n",
      "(69, 583, 777)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                 | 0/69 [00:00<?, ?it/s]\u001b[AException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    /cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "self._shutdown_workers()/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "    /cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "Traceback (most recent call last):\n",
      "if w.is_alive():Exception ignored in: /cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "        self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: \n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>    \n",
      "self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "        if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "if w.is_alive():\n",
      "self._shutdown_workers()\n",
      "\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
      "\n",
      "AssertionError  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      ": Traceback (most recent call last):\n",
      "      File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "can only test a child process    \n",
      "self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "      File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "self._shutdown_workers()AssertionError\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      ": can only test a child process    \n",
      "if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()Exception ignored in: Exception ignored in: /cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "if w.is_alive():  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "\n",
      "    AssertionError  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "self._shutdown_workers(): \n",
      "\n",
      "can only test a child processTraceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    \n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "AssertionErrorif w.is_alive():    self._shutdown_workers(): can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>Traceback (most recent call last):\n",
      "\n",
      "\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "      File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "self._shutdown_workers()    \n",
      "self._shutdown_workers()  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "      File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "if w.is_alive():    \n",
      "if w.is_alive():  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "      File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'    self._shutdown_workers()\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError      File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      ": if w.is_alive():    can only test a child process\n",
      "if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "        \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      ":   File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "AssertionError/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      ": can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Exception ignored in: \n",
      "AssertionErrorcan only test a child process    <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      ":     can only test a child processTraceback (most recent call last):\n",
      ": \n",
      "self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Exception ignored in: Exception ignored in: can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>    \n",
      "\n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "    if w.is_alive():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self._shutdown_workers()/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "        if w.is_alive():self._shutdown_workers()  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Exception ignored in: \n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    \n",
      "if w.is_alive():    Traceback (most recent call last):\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>                AssertionError\n",
      "if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "AssertionError    : assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "self._shutdown_workers()AssertionError: \n",
      "\n",
      ":   File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "can only test a child process    \n",
      "if w.is_alive():\n",
      "Traceback (most recent call last):\n",
      "AssertionError  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "can only test a child process    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: \n",
      ": Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    Exception ignored in: self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "      File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440><function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "        can only test a child process\n",
      "self._shutdown_workers()    Exception ignored in: \n",
      "if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "        if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "\n",
      "AssertionError: can only test a child process\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "Exception ignored in: \n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>AssertionError\n",
      ": Traceback (most recent call last):\n",
      "can only test a child process  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "\n",
      "      File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "self._shutdown_workers()            self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "\n",
      "\n",
      "AssertionError: if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "can only test a child process    \n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "    Exception ignored in: Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError      File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      ":     can only test a child processself._shutdown_workers()\n",
      "\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "if w.is_alive():    Exception ignored in: \n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "    if w.is_alive():  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "AssertionError\n",
      ": can only test a child process\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "    if w.is_alive():  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      ": can only test a child process\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "Traceback (most recent call last):\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ae71169f440>\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/cluster/home/alpaul/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/cluster/home/alpaul/miniconda3/envs/aml/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "\n",
      "  1%|                                                                                       | 1/69 [00:05<05:46,  5.10s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  3%|                                                                                      | 2/69 [00:08<04:44,  4.24s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  4%|                                                                                     | 3/69 [00:12<04:20,  3.95s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  6%|                                                                                   | 4/69 [00:16<04:09,  3.83s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  7%|                                                                                  | 5/69 [00:19<04:01,  3.77s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  9%|                                                                                 | 6/69 [00:23<03:54,  3.72s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 10%|                                                                                | 7/69 [00:26<03:48,  3.69s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 12%|                                                                              | 8/69 [00:30<03:44,  3.67s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 13%|                                                                             | 9/69 [00:34<03:37,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      " 13%|                                                                             | 9/69 [00:37<04:11,  4.19s/it]\n",
      " 15%|                                                                           | 3/20 [01:50<10:27, 36.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prediction list: (10, 583, 777)\n",
      "shape of prediction list: (583, 777, 10)\n",
      "(61, 582, 851)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                 | 0/61 [00:00<?, ?it/s]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  2%|                                                                                       | 1/61 [00:03<03:33,  3.55s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  3%|                                                                                      | 2/61 [00:07<03:32,  3.59s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  5%|                                                                                    | 3/61 [00:10<03:28,  3.59s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  7%|                                                                                   | 4/61 [00:14<03:26,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  8%|                                                                                 | 5/61 [00:18<03:21,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 10%|                                                                                | 6/61 [00:21<03:18,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 11%|                                                                              | 7/61 [00:25<03:14,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 13%|                                                                             | 8/61 [00:28<03:11,  3.61s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 15%|                                                                           | 9/61 [00:32<03:05,  3.57s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      " 15%|                                                                           | 9/61 [00:35<03:27,  3.99s/it]\n",
      " 20%|                                                                       | 4/20 [02:26<09:44, 36.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prediction list: (10, 582, 851)\n",
      "shape of prediction list: (582, 851, 10)\n",
      "(53, 732, 845)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                 | 0/53 [00:00<?, ?it/s]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  2%|                                                                                       | 1/53 [00:03<03:11,  3.68s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  4%|                                                                                     | 2/53 [00:07<03:05,  3.64s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  6%|                                                                                    | 3/53 [00:10<03:02,  3.64s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  8%|                                                                                  | 4/53 [00:14<02:57,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  9%|                                                                                | 5/53 [00:18<02:54,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 11%|                                                                               | 6/53 [00:21<02:50,  3.62s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 13%|                                                                             | 7/53 [00:25<02:46,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 15%|                                                                           | 8/53 [00:28<02:41,  3.59s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 17%|                                                                          | 9/53 [00:32<02:38,  3.61s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      " 17%|                                                                          | 9/53 [00:36<02:56,  4.02s/it]\n",
      " 25%|                                                                  | 5/20 [03:02<09:05, 36.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prediction list: (10, 732, 845)\n",
      "shape of prediction list: (732, 845, 10)\n",
      "(84, 583, 809)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                 | 0/84 [00:00<?, ?it/s]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  1%|                                                                                        | 1/84 [00:03<05:01,  3.64s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  2%|                                                                                       | 2/84 [00:07<04:56,  3.61s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  4%|                                                                                     | 3/84 [00:10<04:52,  3.61s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  5%|                                                                                    | 4/84 [00:14<04:48,  3.61s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  6%|                                                                                   | 5/84 [00:18<04:45,  3.62s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  7%|                                                                                  | 6/84 [00:21<04:40,  3.59s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  8%|                                                                                 | 7/84 [00:25<04:38,  3.61s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 10%|                                                                                | 8/84 [00:28<04:34,  3.62s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 11%|                                                                               | 9/84 [00:32<04:30,  3.61s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      " 11%|                                                                               | 9/84 [00:36<05:00,  4.00s/it]\n",
      " 30%|                                                              | 6/20 [03:38<08:27, 36.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prediction list: (10, 583, 809)\n",
      "shape of prediction list: (583, 809, 10)\n",
      "(78, 582, 737)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                 | 0/78 [00:00<?, ?it/s]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  1%|                                                                                       | 1/78 [00:03<04:37,  3.61s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  3%|                                                                                      | 2/78 [00:07<04:31,  3.57s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  4%|                                                                                     | 3/78 [00:10<04:28,  3.58s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  5%|                                                                                    | 4/78 [00:14<04:25,  3.58s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  6%|                                                                                   | 5/78 [00:17<04:20,  3.57s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  8%|                                                                                  | 6/78 [00:21<04:18,  3.58s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  9%|                                                                                 | 7/78 [00:25<04:15,  3.59s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 10%|                                                                               | 8/78 [00:28<04:11,  3.59s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 12%|                                                                              | 9/78 [00:32<04:08,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      " 12%|                                                                              | 9/78 [00:35<04:34,  3.98s/it]\n",
      " 35%|                                                         | 7/20 [04:14<07:49, 36.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prediction list: (10, 582, 737)\n",
      "shape of prediction list: (582, 737, 10)\n",
      "(125, 587, 775)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                | 0/125 [00:00<?, ?it/s]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  1%|                                                                                       | 1/125 [00:03<07:27,  3.61s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  2%|                                                                                      | 2/125 [00:07<07:22,  3.59s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  2%|                                                                                      | 3/125 [00:10<07:21,  3.62s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  3%|                                                                                     | 4/125 [00:14<07:14,  3.59s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  4%|                                                                                    | 5/125 [00:17<07:09,  3.58s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  5%|                                                                                   | 6/125 [00:21<07:06,  3.58s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  6%|                                                                                   | 7/125 [00:25<07:03,  3.59s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  6%|                                                                                  | 8/125 [00:28<06:56,  3.56s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  7%|                                                                                 | 9/125 [00:32<06:52,  3.56s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "  7%|                                                                                 | 9/125 [00:35<07:41,  3.98s/it]\n",
      " 40%|                                                     | 8/20 [04:49<07:12, 36.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prediction list: (10, 587, 775)\n",
      "shape of prediction list: (587, 775, 10)\n",
      "(76, 730, 956)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                 | 0/76 [00:00<?, ?it/s]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  1%|                                                                                       | 1/76 [00:03<04:25,  3.54s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  3%|                                                                                      | 2/76 [00:07<04:26,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  4%|                                                                                     | 3/76 [00:10<04:24,  3.62s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  5%|                                                                                    | 4/76 [00:14<04:21,  3.64s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  7%|                                                                                   | 5/76 [00:17<04:14,  3.59s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  8%|                                                                                  | 6/76 [00:21<04:13,  3.62s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  9%|                                                                                | 7/76 [00:25<04:09,  3.62s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 11%|                                                                               | 8/76 [00:28<04:07,  3.64s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 12%|                                                                              | 9/76 [00:32<04:01,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      " 12%|                                                                              | 9/76 [00:36<04:28,  4.01s/it]\n",
      " 45%|                                                 | 9/20 [05:26<06:36, 36.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prediction list: (10, 730, 956)\n",
      "shape of prediction list: (730, 956, 10)\n",
      "(104, 587, 781)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                | 0/104 [00:00<?, ?it/s]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  1%|                                                                                       | 1/104 [00:03<06:09,  3.58s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  2%|                                                                                      | 2/104 [00:07<06:06,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  3%|                                                                                     | 3/104 [00:10<06:04,  3.61s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  4%|                                                                                    | 4/104 [00:14<06:03,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  5%|                                                                                   | 5/104 [00:18<05:59,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  6%|                                                                                   | 6/104 [00:21<05:55,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  7%|                                                                                  | 7/104 [00:25<05:49,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  8%|                                                                                 | 8/104 [00:28<05:43,  3.58s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  9%|                                                                                | 9/104 [00:32<05:40,  3.59s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "  9%|                                                                                | 9/104 [00:36<06:20,  4.01s/it]\n",
      " 50%|                                            | 10/20 [06:02<06:00, 36.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prediction list: (10, 587, 781)\n",
      "shape of prediction list: (587, 781, 10)\n",
      "(68, 583, 681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                 | 0/68 [00:00<?, ?it/s]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  1%|                                                                                       | 1/68 [00:03<03:59,  3.57s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  3%|                                                                                      | 2/68 [00:07<03:54,  3.56s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  4%|                                                                                     | 3/68 [00:10<03:51,  3.57s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  6%|                                                                                   | 4/68 [00:14<03:49,  3.58s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  7%|                                                                                  | 5/68 [00:17<03:46,  3.59s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  9%|                                                                                 | 6/68 [00:21<03:43,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 10%|                                                                               | 7/68 [00:25<03:40,  3.62s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 12%|                                                                              | 8/68 [00:28<03:37,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      " 13%|                                                                             | 9/68 [00:32<03:34,  3.63s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      " 13%|                                                                             | 9/68 [00:36<03:57,  4.02s/it]\n",
      " 55%|                                       | 11/20 [06:38<05:24, 36.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of prediction list: (10, 583, 681)\n",
      "shape of prediction list: (583, 681, 10)\n",
      "(90, 587, 713)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                 | 0/90 [00:00<?, ?it/s]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  1%|                                                                                        | 1/90 [00:03<05:20,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  2%|                                                                                       | 2/90 [00:07<05:17,  3.60s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  3%|                                                                                      | 3/90 [00:10<05:14,  3.61s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  4%|                                                                                     | 4/90 [00:14<05:11,  3.62s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "\n",
      "  6%|                                                                                    | 5/90 [00:17<05:04,  3.58s/it]\u001b[A/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "/cluster/home/alpaul/MitralValveSegmentation/mvseg/mvseg/datasets/base_dataset.py:59: UserWarning: An output with one or more elements was resized since it had shape [50176], which does not match the required output shape [1, 1, 224, 224].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n",
      "  return torch.stack(batch, 0, out=out)\n",
      "  6%|                                                                                    | 5/90 [00:19<05:24,  3.82s/it]\n",
      " 55%|                                       | 11/20 [06:57<05:41, 37.95s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22624/3517578304.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_video_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0md_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frame_number'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mmask_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mdeliver_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'md5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdigest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWELCOME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_directory = '/cluster/home/alpaul/videos'\n",
    "threshold = 0.7\n",
    "fps = 10\n",
    "predictions = []\n",
    "\n",
    "for d in tqdm(test_data):\n",
    "\n",
    "    d_video_frames = np.moveaxis(d['video'], -1, 0)\n",
    "    print(d_video_frames.shape)\n",
    "    height, width = d_video_frames.shape[1], d_video_frames.shape[2]\n",
    "    out = cv2.VideoWriter(f'{output_directory}/{d[\"name\"]}_{threshold}.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height), False)\n",
    "    prediction = []\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for idx in tqdm(range(len(d_video_frames))):\n",
    "            count += 1\n",
    "            d_im = list(filter(lambda p : p['frame_number'] == idx and p['video'][0] == d['name'], test_loader))[0]\n",
    "            pred = model(d_im)\n",
    "            mask_pred = pred['seg'].squeeze(0).squeeze(0)\n",
    "            h,w = d_im['hw'] # height to resize to\n",
    "            mask_pred = torch.tensor(resize(mask_pred, (h[0],w[0]), anti_aliasing=True))\n",
    "            mask_pred = torch.gt(mask_pred, threshold)\n",
    "            mask_pred = mask_pred.numpy().astype('bool')\n",
    "            im = d_im['image'].squeeze(0).squeeze(0)\n",
    "            im = resize(im, (h[0],w[0]), anti_aliasing=True)\n",
    "            assert im.shape == mask_pred.shape\n",
    "            im = im * 255\n",
    "            im[mask_pred] = 255\n",
    "            im = im.astype('uint8')\n",
    "            prediction.append(mask_pred)\n",
    "            out.write(im.astype('uint8'))\n",
    "#             plt.imshow(mask_pred.astype('float32')*255)\n",
    "#             print(np.max(mask_pred.astype('uint8')*255))\n",
    "    out.release()\n",
    "    del out\n",
    "    print(f\"shape of prediction list: {np.array(prediction).shape}\")\n",
    "    prediction = np.moveaxis(prediction, 0, -1)\n",
    "    print(f\"shape of prediction list: {prediction.shape}\")\n",
    "    predictions.append({\n",
    "        'name': d['name'],\n",
    "        'prediction': prediction\n",
    "        }\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in correct format\n",
    "save_zipped_pickle(predictions, 'my_predictions_0.7_retrain.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(586, 821)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(587, 791)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(583, 777)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(582, 851)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(732, 845)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(583, 809)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(582, 737)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(587, 775)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(730, 956)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(587, 781)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(583, 681)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 713)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 612)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(587, 773)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(707, 855)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(731, 1007)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 780)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(583, 670)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(594, 745)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n",
      "(583, 779)\n"
     ]
    }
   ],
   "source": [
    "# # Debugging\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# test_data = load_zipped_pickle( '/cluster/project/infk/cvg/students/alpaul/MitralValveSegmentation/data/test.pkl')\n",
    "# b = False\n",
    "# items = []\n",
    "# for data in test_data:\n",
    "#     video = np.moveaxis(data['video'], -1, 0)\n",
    "#     for i, im in enumerate(video):\n",
    "#         print(im.shape)\n",
    "#         continue\n",
    "#         if not (im.shape[0] == im.shape[1] == 112):\n",
    "#             im = resize(im, (112, 112), anti_aliasing=True)\n",
    "#             # here check what happens\n",
    "#             b = True\n",
    "        \n",
    "#         im = torch.from_numpy(im / 255.).float().unsqueeze(0)\n",
    "        \n",
    "#         # here check what happens\n",
    "#         print(type(im))\n",
    "#         items.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
